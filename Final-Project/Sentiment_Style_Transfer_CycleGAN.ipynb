{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qhD8sBculJG4"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Iterable, List\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from torchtext.data.metrics import bleu_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Code built with the help of: https://pytorch.org/tutorials/beginner/translation_transformer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh4cf1welVUW",
        "outputId": "d3b1ad08-0f2f-4c36-9257-77cc1dd3fd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EKNET6CPlVtE"
      },
      "outputs": [],
      "source": [
        "FOLDER_PATH = '/drive/My Drive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K7UAXKOHlX_b"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, sentiment) -> None:\n",
        "        super().__init__()\n",
        "        data_df = pd.read_csv(filename)\n",
        "        data_df['sentiment'] = data_df['sentiment'].apply(lambda x: 2 if x == 'pos' else 1)\n",
        "        data_df['pair'] = list(zip(data_df['sentiment'], data_df['text']))\n",
        "\n",
        "        if sentiment == 'pos':\n",
        "            self.data = data_df['pair'][data_df['sentiment'] == 2].values.tolist()\n",
        "        else:\n",
        "            self.data = data_df['pair'][data_df['sentiment'] == 1].values.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jVjtOo5AlaPs"
      },
      "outputs": [],
      "source": [
        "SENTIMENT_POS = 'pos'\n",
        "SENTIMENT_NEG = 'neg'\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab_transform = {}\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "##### POSITIVE SENTIMENT VOCAB #####\n",
        "train_iter_pos = IMDBDataset(f'{FOLDER_PATH}train.csv', SENTIMENT_POS)\n",
        "vocab_transform[SENTIMENT_POS] = build_vocab_from_iterator(yield_tokens(train_iter_pos),\n",
        "                                                min_freq=1,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True)\n",
        "vocab_transform[SENTIMENT_POS].set_default_index(UNK_IDX)\n",
        "\n",
        "##### NEGATIVE SENTIMENT VOCAB #####\n",
        "train_iter_neg = IMDBDataset(f'{FOLDER_PATH}test.csv', SENTIMENT_NEG)\n",
        "vocab_transform[SENTIMENT_NEG] = build_vocab_from_iterator(yield_tokens(train_iter_neg),\n",
        "                                                min_freq=1,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True)\n",
        "vocab_transform[SENTIMENT_NEG].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7AFM4BaleJb",
        "outputId": "9e7f75be-2559-4a4c-ab7e-f055f8c43729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TvrpaaHblefj"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UWVNIu-YmJN3"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, emb_size, dropout: float = 0.1):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.embedding = TokenEmbedding(vocab_size, emb_size)\n",
        "    self.fc = nn.Linear(emb_size, 1)\n",
        "    self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.positional_encoding(self.embedding(x))\n",
        "    out = nn.sigmoid(self.Linear(x))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rT6lAahJlhQq"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0cTbWKJgIcTx"
      },
      "outputs": [],
      "source": [
        "def real_mse_loss(out, adverserial_weight=1):\n",
        "    return torch.mean((out-1)**2)*adverserial_weight\n",
        "\n",
        "def fake_mse_loss(out, adverserial_weight=1):\n",
        "    return torch.mean(out**2)*adverserial_weight\n",
        "\n",
        "def calc_cycle_loss(real_text, reconstructed_text, lambda_weight=1):\n",
        "    return torch.mean(torch.abs(real_text - reconstructed_text))*lambda_weight\n",
        "\n",
        "def calc_identity_loss(real_text, generated_text, identity_weight=1):\n",
        "    return torch.mean(torch.abs(real_text - generated_text))*identity_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yYbq-pQelk_9"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "POS_VOCAB_SIZE = len(vocab_transform[SENTIMENT_POS])\n",
        "NEG_VOCAB_SIZE = len(vocab_transform[SENTIMENT_NEG])\n",
        "EMB_SIZE = 64\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 64\n",
        "BATCH_SIZE = 1\n",
        "NUM_ENCODER_LAYERS = 1\n",
        "NUM_DECODER_LAYERS = 1\n",
        "\n",
        "G_POS_to_NEG = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, POS_VOCAB_SIZE, NEG_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "G_NEG_to_POS = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, NEG_VOCAB_SIZE, POS_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "D_NEG = Discriminator(NEG_VOCAB_SIZE, EMB_SIZE)\n",
        "D_POS = Discriminator(POS_VOCAB_SIZE, EMB_SIZE)\n",
        "\n",
        "for p in G_POS_to_NEG.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "for p in G_NEG_to_POS.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "for p in D_NEG.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "for p in D_POS.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "G_POS_to_NEG = G_POS_to_NEG.to(DEVICE)\n",
        "G_NEG_to_POS = G_NEG_to_POS.to(DEVICE)\n",
        "D_NEG = D_NEG.to(DEVICE)\n",
        "D_POS = D_POS.to(DEVICE)\n",
        "\n",
        "loss_fn_g = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "loss_fn_d = nn.BCELoss()\n",
        "optimizer_g = torch.optim.Adam(list(G_POS_to_NEG.parameters()) + list(G_NEG_to_POS.parameters()), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "optimizer_d_pos = torch.optim.Adam(D_POS.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "optimizer_d_neg = torch.optim.Adam(D_NEG.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "janoN_fKlnBY",
        "outputId": "a9cd804d-f235-4ba8-96c7-3791a872e2b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35375910"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in G_NEG_to_POS.parameters() if p.requires_grad) \\\n",
        "  +sum(p.numel() for p in G_POS_to_NEG.parameters() if p.requires_grad)+sum(p.numel() for p in D_NEG.parameters() if p.requires_grad)+\\\n",
        "    sum(p.numel() for p in D_POS.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iCnbdlr1lnaI"
      },
      "outputs": [],
      "source": [
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SENTIMENT_POS, SENTIMENT_NEG]:\n",
        "    text_transform[ln] = sequential_transforms(tokenizer,\n",
        "                                               vocab_transform[ln],\n",
        "                                               tensor_transform)\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    text_batch = []\n",
        "    for label, text in batch:\n",
        "        if label == 1:\n",
        "            text_batch.append(text_transform[SENTIMENT_NEG](text.rstrip(\"\\n\")))\n",
        "        else:\n",
        "            text_batch.append(text_transform[SENTIMENT_POS](text.rstrip(\"\\n\")))\n",
        "\n",
        "    text_batch = pad_sequence(text_batch, padding_value=PAD_IDX)\n",
        "    return text_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Sgtoq2C6lqa2"
      },
      "outputs": [],
      "source": [
        "def train_epoch():\n",
        "    G_POS_to_NEG.train()\n",
        "    G_NEG_to_POS.train()\n",
        "\n",
        "    losses = 0\n",
        "    train_iter_pos = IMDBDataset(f'{FOLDER_PATH}train.csv', SENTIMENT_POS)\n",
        "    train_iter_neg = IMDBDataset(f'{FOLDER_PATH}train.csv', SENTIMENT_NEG)\n",
        "    train_pos_dataloader = DataLoader(train_iter_pos, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    train_neg_dataloader = DataLoader(train_iter_neg, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    \n",
        "    for pos, neg in zip(train_pos_dataloader, train_neg_dataloader):\n",
        "        pos = pos.to(DEVICE)\n",
        "        neg = neg.to(DEVICE)\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                        Train the generator                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        neg_input = neg[:-1, :]\n",
        "        pos_input = pos[:-1, :]\n",
        "        pos_mask1, neg_mask1, pos_padding_mask1, neg_padding_mask1 = create_mask(pos, neg_input)\n",
        "        neg_mask2, pos_mask2, neg_padding_mask2, pos_padding_mask2 = create_mask(neg, pos_input)\n",
        "        fake_neg = G_POS_to_NEG(pos, neg_input, pos_mask1, neg_mask1, pos_padding_mask1, neg_padding_mask1, pos_padding_mask1)\n",
        "        fake_pos = G_NEG_to_POS(neg, pos_input, neg_mask2, pos_mask2, neg_padding_mask2, pos_padding_mask2, neg_padding_mask2)\n",
        "\n",
        "        neg_out = neg[1:, :]\n",
        "        generator_loss_pos = loss_fn_g(fake_neg.reshape(-1, fake_neg.shape[-1]), neg_out.reshape(-1))\n",
        "\n",
        "        pos_out = pos[1:, :]\n",
        "        generator_loss_neg = loss_fn_g(fake_pos.reshape(-1, fake_pos.shape[-1]), pos_out.reshape(-1))\n",
        "        \n",
        "        fake_neg_input = fake_neg[:-1, :]\n",
        "        fake_pos_input = fake_pos[:-1, :]\n",
        "        fake_pos_mask1, fake_neg_mask1, fake_pos_padding_mask1, fake_neg_padding_mask1 = create_mask(fake_pos, fake_neg_input)\n",
        "        fake_neg_mask2, fake_pos_mask2, fake_neg_padding_mask2, fake_pos_padding_mask2 = create_mask(fake_neg, fake_pos_input)\n",
        "        cycle_pos = G_NEG_to_POS(fake_neg, fake_pos_input, fake_neg_mask2, fake_pos_mask2, fake_neg_padding_mask2, fake_pos_padding_mask2, \\\n",
        "                                 fake_neg_padding_mask2)\n",
        "        cycle_neg = G_POS_to_NEG(fake_pos, fake_neg_input, fake_pos_mask1, fake_neg_mask1, fake_pos_padding_mask1, fake_neg_padding_mask1, \\\n",
        "                                 fake_pos_padding_mask1)\n",
        "        \n",
        "        total_cycle_loss = calc_cycle_loss(pos, cycle_pos) + calc_cycle_loss(neg, cycle_neg)\n",
        "\n",
        "        same_pos = G_NEG_to_POS(pos, neg_input, pos_mask2, neg_mask2, pos_padding_mask2, neg_padding_mask2, pos_padding_mask2)\n",
        "        same_neg = G_POS_to_NEG(neg, pos_input, neg_mask1, pos_mask1, neg_padding_mask1, pos_padding_mask1, neg_padding_mask1)\n",
        "\n",
        "        identity_loss = calc_identity_loss(pos, same_pos) + calc_identity_loss(neg, same_neg)\n",
        "\n",
        "        total_generator_loss = generator_loss_pos.item() + generator_loss_neg.item() + total_cycle_loss + identity_loss\n",
        "        total_generator_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                        Train the discriminator                     #\n",
        "        # ================================================================== #\n",
        "\n",
        "        optimizer_d_pos.zero_grad()\n",
        "        optimizer_d_neg.zero_grad()\n",
        "\n",
        "        disc_real_pos = D_POS(pos)\n",
        "        disc_real_neg = D_NEG(neg)\n",
        "\n",
        "        disc_fake_pos = D_POS(fake_pos)\n",
        "        disc_fake_neg = D_NEG(fake_neg)\n",
        "\n",
        "        disc_pos_loss = loss_fn_d(disc_real_pos, disc_fake_pos)\n",
        "        disc_neg_loss = loss_fn_d(disc_real_neg, disc_fake_neg)\n",
        "\n",
        "        disc_pos_loss.backward()\n",
        "        disc_neg_loss.backward()\n",
        "\n",
        "        optimizer_d_pos.step()\n",
        "        optimizer_d_neg.step()\n",
        "        losses += total_generator_loss\n",
        "\n",
        "    return losses / len(list(train_pos_dataloader))\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    G_POS_to_NEG.eval()\n",
        "    G_NEG_to_POS.eval()\n",
        "    losses = 0\n",
        "\n",
        "    test_iter_pos = IMDBDataset(f'{FOLDER_PATH}test.csv', SENTIMENT_POS)\n",
        "    test_iter_neg = IMDBDataset(f'{FOLDER_PATH}test.csv', SENTIMENT_NEG)\n",
        "    test_pos_dataloader = DataLoader(test_iter_pos, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    test_neg_dataloader = DataLoader(test_iter_neg, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    \n",
        "    for src, tgt in zip(test_pos_dataloader, test_neg_dataloader):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(test_pos_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "VbZz729_lsqk",
        "outputId": "a2286d76-3881-4bd5-a269-6bd95ca10ef1"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d85cd18c94ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#val_loss = evaluate(G_NEG_to_POS, 'neg_to_pos')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-a68647176dc5>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfake_pos_mask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_neg_mask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_pos_padding_mask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_neg_padding_mask1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_neg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mfake_neg_mask2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_pos_mask2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_neg_padding_mask2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_pos_padding_mask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_pos_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         cycle_pos = G_NEG_to_POS(fake_neg, fake_pos_input, fake_neg_mask2, fake_pos_mask2, fake_neg_padding_mask2, fake_pos_padding_mask2, \\\n\u001b[0m\u001b[1;32m     40\u001b[0m                                  fake_neg_padding_mask2)\n\u001b[1;32m     41\u001b[0m         cycle_neg = G_POS_to_NEG(fake_pos, fake_neg_input, fake_pos_mask1, fake_neg_mask1, fake_pos_padding_mask1, fake_neg_padding_mask1, \\\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e5756d2e24a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mtgt_padding_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 memory_key_padding_mask: Tensor):\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0msrc_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mtgt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e5756d2e24a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_embedding)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embedding\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtoken_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 43.55 GiB (GPU 0; 14.76 GiB total capacity; 1.08 GiB already allocated; 12.89 GiB free; 1.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch()\n",
        "    end_time = timer()\n",
        "    #val_loss = evaluate(G_NEG_to_POS, 'neg_to_pos')\n",
        "    #print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f} \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "\n",
        "# function to generate output sequence using greedy algorithm\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "def transfer(model: torch.nn.Module, src_sentence: str, transfer_direction: str):\n",
        "    model.eval()\n",
        "    if transfer_direction == 'neg_to_pos':\n",
        "        src = text_transform[SENTIMENT_NEG](src_sentence).view(-1, 1)\n",
        "        num_tokens = src.shape[0]\n",
        "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "        tgt_tokens = greedy_decode(\n",
        "            model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "        return \" \".join(vocab_transform[SENTIMENT_POS].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "    else:\n",
        "        src = text_transform[SENTIMENT_POS](src_sentence).view(-1, 1)\n",
        "        num_tokens = src.shape[0]\n",
        "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "        tgt_tokens = greedy_decode(\n",
        "            model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "        return \" \".join(vocab_transform[SENTIMENT_NEG].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joNfbk5-lyai"
      },
      "outputs": [],
      "source": [
        "print(transfer(G_NEG_to_POS, \"This movie sucks.\", 'neg_to_pos'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzfvn1Qkl0HI"
      },
      "outputs": [],
      "source": [
        "torch.save(G_NEG_to_POS.state_dict(), f'{FOLDER_PATH}G_NEG_to_POS.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
